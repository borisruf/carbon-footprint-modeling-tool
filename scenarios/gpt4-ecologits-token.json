{
  "title": "GPT-4 emission per token (EcoLogits)",
  "description" : "The nonprofit organization <a href='https://genai-impact.org' target='_blank'>GenAI Impact</a> takes GPU and server power consumption into account when modeling AI model emissions. In both cases, they use the open dataset from the <a href='https://huggingface.co/spaces/optimum/llm-perf-leaderboard' target='_blank'>LLM Perf Leaderboard</a> produced by Hugging Face. For closed models such as GPT-4, where the data is not available, they fit linear regression models that model the energy consumption per output token as a function of the number of active parameters.<br/><br/>For the GPT-4o-mini model, which utilizes a Mixture of Experts (MoE) architecture, the following assumptions are made:<br/><br/>Total parameters: 1760 billion<br/>Active parameters: 880 billion<br/><br/>To assess server energy consumption excluding GPUs, they fit linear regression model to estimate the token generation latency.<br/><br/>See the <a href='https://ecologits.ai/latest/methodology/llm_inference/' target='_blank'>full documentation</a> for a comprehensive overview of the methodology.",
  "scopes": [
    {
      "level": "Scope 2",
      "description": {},
      "list": [ 
    {
          "type": "link",
      "quantity": 1.2,
          "scenario_id": "gpt4-ecologits-token-2"
        }
      ]
    }
  ]
}