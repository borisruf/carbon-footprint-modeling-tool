{
    "title": "BLOOM model experiment",
    "description": "Alexandra Sasha Luccioni et al. published a <a href='https://arxiv.org/pdf/2211.02001.pdf' target='_blank'>study</a> on the the carbon footprint of the <a href='https://bigscience.huggingface.co/blog/bloom' target='_blank'>BLOOM model</a>. With its 176 billion parameters, BLOOM is a large language model (LLM) that is able to generate text in 46 natural languages and 13 programming languages. The researchers ran their experiment on 16 Nvidia A100 GPUs during 18 days. The model handled <b>230,768 queries</b> in the course of the experiment. In total, the system consumed <b>914 kWh</b> of electriciy for CPU, RAM and GPU usage.<br/><br/>For the emissions, we used a grid emissions factor for Western USA (WECC) from <a href='https://www.cloudcarbonfootprint.org/docs/methodology/#azure-2' target='_blank'>EPA</a>.  ",
    "scopes": [
      {
        "level": "Scope 3",
        "description": {},
        "list": [
          {
            "type": "component",
            "consumer": {
              "name": "Experiment",
              "description": "BLOOM model API running on 16 Nvidia A100 GPUs",
              "consumptions": {
                "electricity": {
                  "value": "914",
                  "unit": "kWh",
                  "base_unit": "experiment",
                  "reference_url": "https://arxiv.org/pdf/2211.02001.pdf"
                }
              }
            },
            "quantity": "1",
            "quantity_unit": "experiment",
            "source": {
              "name": "Western USA electricity grid",
              "type": "electricity",
              "description": "(2021)",
              "emissions": {
                "co2e": {
                  "value": "0.322167",
                  "unit": "kg",
                  "base_unit": "kWh",
                  "reference_url": "https://www.epa.gov/egrid/download-data"
                }
              }
            }
          }
        ]
      }
    ]
  }
  