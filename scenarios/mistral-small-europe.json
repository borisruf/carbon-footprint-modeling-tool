{
    "title": "1 token of Mistral Small in Europe",
    "description": "The <a href='https://huggingface.co/spaces/optimum/llm-perf-leaderboard' target='_blank'>Hugging Face LLM-Perf Leaderboard</a> benchmarks the performance of large language models (LLMs). Energy consumption is measured using <a href='https://mlco2.github.io/codecarbon/index.html' target='_blank'>CodeCarbon</a>. We suggest that <a href='https://openrouter.ai/models/mistralai/mistral-small/api'  target='_blank'>Mistral Small is equivalent to Mistrall 7B v0.1</a> on Huggingface. We observe that the most energy efficient Mistral 7B model with 7B parameters handles 387,772 completion tokens/kWh. Per token, that's 1/163934 = <a href='https://www.google.com/search?q=1%2F387772' target='_blank'>2.58e-6</a> kWh.",
    "scopes": [
      {
        "level": "Scope 3",
        "description": {},
        "list": [
          {
            "type": "component",
            "consumer": {
              "name": "kWh/token",
              "description": "Mistral 7B v0.1",
              "consumptions": {
                "electricity": {
                  "value": "0.00000257883",
                  "unit": "kWh",
                  "base_unit": "token",
                  "reference_url": "https://huggingface.co/spaces/optimum/llm-perf-leaderboard"
                }
              }
            },
            "quantity": "1",
            "quantity_unit": "token",
            "source": {
              "name": "Microsoft Europe average electricity grid",
              "type": "electricity",
              "description": "(2024 intern data)",
              "emissions": {
                "co2e": {
                  "value": "0.24845",
                  "unit": "kg",
                  "base_unit": "kWh",
                  "reference_url": "https://www.iea.org/data-and-statistics"
                }
              }
            }
          }
        ]
      }
    ]
  }
  