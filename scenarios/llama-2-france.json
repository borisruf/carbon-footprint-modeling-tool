{
    "title": "1 token of Llama 2 in France",
    "description": "The <a href='https://huggingface.co/spaces/optimum/llm-perf-leaderboard' target='_blank'>Hugging Face LLM-Perf Leaderboard</a> benchmarks the performance of large language models (LLMs). Energy consumption is measured using <a href='https://mlco2.github.io/codecarbon/index.html' target='_blank'>CodeCarbon</a>. We observe that the most energy efficient Llama 2 model with 70B parameters handles 163,934 completion tokens/kWh. Per token, that's 1/163934 = <a href='https://www.google.com/search?q=1%2F163934' target='_blank'>6.1e-6</a> kWh.",
    "scopes": [
      {
        "level": "Scope 3",
        "description": {},
        "list": [
          {
            "type": "component",
            "consumer": {
              "name": "kWh/token",
              "description": "Llama 2 68.98B parameters",
              "consumptions": {
                "electricity": {
                  "value": "0.00000610001586",
                  "unit": "kWh",
                  "base_unit": "token",
                  "reference_url": "https://huggingface.co/spaces/optimum/llm-perf-leaderboard"
                }
              }
            },
            "quantity": "1",
            "quantity_unit": "token",
            "source": {
              "name": "France electricity grid",
              "type": "electricity",
              "description": "(2024 intern data)",
              "emissions": {
                "co2e": {
                  "value": "0.0814",
                  "unit": "kg",
                  "base_unit": "kWh",
                  "reference_url": "https://www.iea.org/data-and-statistics"
                }
              }
            }
          }
        ]
      }
    ]
  }
  
