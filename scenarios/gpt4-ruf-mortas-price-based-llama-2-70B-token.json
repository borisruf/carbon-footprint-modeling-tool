{
  "title": "GPT-4 emission per token (Ruf & Mortas)",
  "description": "In the absence of reliable data on the energy consumption of GPT-4, this information is extrapolated from the estimations made for GPT-3. We don't have any official information on the number of parameters of GPT-4, so we can make a guess based on the price of tokens processing for both models. However, you need a <a href=\"https://www.greaterwrong.com/posts/PLf7tvzujaJ2A2r7N/what-the-cost-difference-in-processing-input-vs-output\" target=\"blank\">lot more memory/memory bandwidth to process an output token than an input token</a>, because to process an output token you also need to fit the KV cache in memory. This known, we'll make our estimations based on the price of output tokens. The <a href=\"https://openai.com/api/pricing/\" target=\"blank\">price</a> of 1 milion output token of gpt-3.5-turbo-0125 is $1.50, whereas for gpt-4-turbo it is $30.<br/><br/>Therefore, we assume that submitting a query to GPT-4 requires <b><a href=\"https://www.google.com/search?q=30/1.5\" target=\"blank\">20x</a> more</b> energy than for GPT-3.5.",
  "scopes": [
    {
      "level": "Scope 3",
      "description": {},
        "list": [
        {
          "type": "link",
          "quantity": 20,
          "scenario_id": "gpt3-ruf-mortas-llama-2-70B-token"
        }
      ]
    }
  ]
}