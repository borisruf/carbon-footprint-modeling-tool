{
    "title": "1 token of Falcon 7B in France",
    "description": "The <a href='https://huggingface.co/spaces/optimum/llm-perf-leaderboard' target='_blank'>Hugging Face LLM-Perf Leaderboard</a> benchmarks the performance of large language models (LLMs). Energy consumption is measured using <a href='https://mlco2.github.io/codecarbon/index.html' target='_blank'>CodeCarbon</a>. We observe that the most energy efficient Falcon model with 7B parameters handles 422,919 completion tokens/kWh. Per token, that's 1/422919 = <a href='https://www.google.com/search?q=1%2F422919' target='_blank'>2.4e-6</a> kWh.",
    "scopes": [
      {
        "level": "Scope 3",
        "description": {},
        "list": [
          {
            "type": "component",
            "consumer": {
              "name": "kWh/token",
              "description": "Falcon 7B parameters",
              "consumptions": {
                "electricity": {
                  "value": "0.00000236451",
                  "unit": "kWh",
                  "base_unit": "token",
                  "reference_url": "https://huggingface.co/spaces/optimum/llm-perf-leaderboard"
                }
              }
            },
            "quantity": "1",
            "quantity_unit": "token",
            "source": {
              "name": "France electricity grid",
              "type": "electricity",
              "description": "(2024 intern data)",
              "emissions": {
                "co2e": {
                  "value": "0.0814",
                  "unit": "kg",
                  "base_unit": "kWh",
                  "reference_url": "https://www.epa.gov/egrid/download-data"
                }
              }
            }
          }
        ]
      }
    ]
  }
  
