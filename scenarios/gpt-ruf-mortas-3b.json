{
    "title": "Llama 3",
    "description": "The <a href='https://huggingface.co/spaces/optimum/llm-perf-leaderboard' target='_blank'>Hugging Face LLM-Perf Leaderboard</a> benchmarks the performance of large language models (LLMs). Energy consumption is measured using <a href='https://mlco2.github.io/codecarbon/index.html' target='_blank'>CodeCarbon</a>. We observe that the most energy efficient Llama 3 model with 8B parameters handles 201,527 completion tokens/kWh. Per token, that's 1/201527 = <a href='https://www.google.com/search?q=1%2F201527' target='_blank'>5.1e-6</a> kWh.",
    "scopes": [
      {
        "level": "Scope 3",
        "description": {},
        "list": [
          {
            "type": "component",
            "consumer": {
              "name": "kWh/token",
              "description": "Llama 2 68.98B parameters",
              "consumptions": {
                "electricity": {
                  "value": "0.00000496211425",	  
                  "unit": "kWh",
                  "base_unit": "token",
                  "reference_url": "https://huggingface.co/spaces/optimum/llm-perf-leaderboard"
                }
              }
            },
            "quantity": "1",
            "quantity_unit": "token",
            "source": {
              "name": "Western USA electricity grid",
              "type": "electricity",
              "description": "(2021)",
              "emissions": {
                "co2e": {
                  "value": "0.322167",
                  "unit": "kg",
                  "base_unit": "kWh",
                  "reference_url": "https://www.epa.gov/egrid/download-data"
                }
              }
            }
          }
        ]
      }
    ]
  }
  
